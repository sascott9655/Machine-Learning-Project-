{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Breast Cancer Image Classification using Convolutional Neural Networks\n",
        "Authors: Dereck Riley, Maria Santiago, Samuel Scott\n",
        "\n",
        "Due: December 16, 2024"
      ],
      "metadata": {
        "id": "UcqFX8ea7o_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In this project, we explore a dataset of breast tissue images focused on Invasive Ductal Carcinoma (IDC), the most common type of breast cancer in women. The dataset consists of labeled images, each marked as either IDC (-) or IDC (+), indicating the presence or absence of cancerous tissue in the sample. The images are organized into patient ID files containing two directories, with folder 0 containing non-IDC images (indicating no cancer present) and folder 1 containing IDC-positive images (indicating the presence of breast cancer).\n",
        "\n",
        "The objective of our project is to build a model that accurately differentiates between IDC-negative and IDC-positive images. By comparing the characteristics of these two categories, we aim to develop a reliable approach for identifying breast cancer cells. This analysis will enable us to explore patterns in the data that could improve diagnostic accuracy, and better detection of breast cancer in medical practice.\n",
        "\n",
        "Our dataset can be found here: https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images\n"
      ],
      "metadata": {
        "id": "xVEPax1w791V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, ParameterGrid\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, Input, Model\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "# Importing Data\n",
        "import kagglehub\n",
        "\n",
        "# Used for Preprocessing\n",
        "import glob\n",
        "import cv2\n",
        "import random\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "OMDTyOdg8QxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Retrieval\n"
      ],
      "metadata": {
        "id": "er7KRbFUcZhh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "9yiRJO_h7ocr",
        "outputId": "eb3d946f-cf40-46f9-cafc-63fef510a9dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.5)\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/paultimothymooney/breast-histopathology-images?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|‚ñç         | 151M/3.10G [00:07<02:38, 20.0MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-11adc50a3431>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Download for the Data Set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"paultimothymooney/breast-histopathology-images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Path to dataset files:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kagglehub/datasets.py\u001b[0m in \u001b[0;36mdataset_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_dataset_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading Dataset: {h.to_url()} ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mEXTRA_CONSOLE_BLOCK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kagglehub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kagglehub/http_resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, h, path, force_download)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;31m# First, we download the archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mapi_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;31m# Create the directory to extract the archive to.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, path, out_file, resource_handle, cached_path)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading from {url}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0m_download_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhash_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36m_download_file\u001b[0;34m(response, out_file, size_read, total_size, hash_object)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_divisor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhash_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    947\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def _raw_read(\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0;31m# clip the read to the \"end of response\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mamt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Download for the Data Set\n",
        "path = kagglehub.dataset_download(\"paultimothymooney/breast-histopathology-images\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "For the preprocessing aspect of our project we:\n",
        "\n",
        "*   categorize IDC(-) and IDC(+) images.\n",
        "*   resize the images to a standard size\n",
        "*   downsize the amount of IDC(-) images\n",
        "*   label them according to their class\n",
        "*   split the data into testing and training sets\n",
        "\n",
        "The purpose for preprocessing our data in this format is to help the model distinguish the images, train on a mixture of both classes, make accurate predictions and generalize new data.\n",
        "\n",
        "Source Used for Segments of Data Preprocessing Code:\n",
        "\n",
        "https://www.kaggle.com/code/thesnak/breast-cancer-classification-96-89"
      ],
      "metadata": {
        "id": "gSWy3ZczV30F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = glob.glob(path + \"/**/*.png\", recursive=True)"
      ],
      "metadata": {
        "id": "_D8v_Oqx-1nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_IDC = []\n",
        "P_IDC = []\n",
        "\n",
        "for img in images:\n",
        "    if img[-5] == '0' :\n",
        "        N_IDC.append(img)\n",
        "\n",
        "    elif img[-5] == '1' :\n",
        "        P_IDC.append(img)\n",
        "\n",
        "num_non = min(len(N_IDC), 18)\n",
        "num_can = min(len(P_IDC), 18)"
      ],
      "metadata": {
        "id": "KBdJQ4h5_vDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_img_arr = []\n",
        "can_img_arr = []\n",
        "NewN_IDC=N_IDC[:78786]\n",
        "\n",
        "for img in NewN_IDC:\n",
        "    n_img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
        "    n_img_size = cv2.resize(n_img, (50, 50), interpolation = cv2.INTER_LINEAR)\n",
        "    non_img_arr.append([n_img_size, 0])\n",
        "\n",
        "for img in P_IDC:\n",
        "    c_img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
        "    c_img_size = cv2.resize(c_img, (50, 50), interpolation = cv2.INTER_LINEAR)\n",
        "    can_img_arr.append([c_img_size, 1])"
      ],
      "metadata": {
        "id": "GLhIv8UXAsp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "# Extract image arrays and labels separately\n",
        "non_img_data = [item[0] for item in non_img_arr]\n",
        "non_img_labels = [item[1] for item in non_img_arr]\n",
        "can_img_data = [item[0] for item in can_img_arr]\n",
        "can_img_labels = [item[1] for item in can_img_arr]\n",
        "\n",
        "# Concatenate image data and labels separately\n",
        "X = np.concatenate((non_img_data, can_img_data))\n",
        "y = np.concatenate((non_img_labels, can_img_labels))\n",
        "\n",
        "# Shuffle data and labels together\n",
        "combined_data = list(zip(X, y))\n",
        "random.shuffle(combined_data)\n",
        "X, y = zip(*combined_data)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "qE_MSyv3B0r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def describeData(a,b):\n",
        "    print('Total number of images: {}'.format(len(a)))\n",
        "    print('Number of IDC(-) Images: {}'.format(np.sum(b==0)))\n",
        "    print('Number of IDC(+) Images: {}'.format(np.sum(b==1)))\n",
        "    print('Image shape (Width, Height, Channels): {}'.format(a[0].shape))\n",
        "describeData(X,y)"
      ],
      "metadata": {
        "id": "ktaXgTLTCBaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes = 2)\n",
        "y_test = to_categorical(y_test, num_classes = 2)\n",
        "\n",
        "print(\"Training Data Shape:\", X_train.shape)\n",
        "print(\"Testing Data Shape:\", X_test.shape)"
      ],
      "metadata": {
        "id": "bYbumHR0CDrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visual\n",
        "\n",
        "- Idea: Plot/Showcase Images of Our Data Set"
      ],
      "metadata": {
        "id": "9KGGGIvoyt9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_random_images(X, y, num_images=5):\n",
        "\n",
        "    # Select IDC(-) and IDC(+) indices\n",
        "    negative_indices = [i for i in range(len(y)) if y[i] == 0]\n",
        "    positive_indices = [i for i in range(len(y)) if y[i] == 1]\n",
        "\n",
        "    random_negative_indices = random.sample(negative_indices, num_images)\n",
        "    random_positive_indices = random.sample(positive_indices, num_images)\n",
        "\n",
        "    # Set up the plot\n",
        "    fig, axs = plt.subplots(2, num_images, figsize=(15, 6))\n",
        "\n",
        "    # Display IDC(-) images\n",
        "    for i, idx in enumerate(random_negative_indices):\n",
        "        ax = axs[0, i]\n",
        "        ax.imshow(cv2.cvtColor(X[idx], cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct display\n",
        "        ax.set_title(\"IDC(-)\")\n",
        "        ax.axis('off')\n",
        "\n",
        "    # Display IDC(+) images\n",
        "    for i, idx in enumerate(random_positive_indices):\n",
        "        ax = axs[1, i]\n",
        "        ax.imshow(cv2.cvtColor(X[idx], cv2.COLOR_BGR2RGB))\n",
        "        ax.set_title(\"IDC(+)\")\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "display_random_images(X, y, num_images=5)"
      ],
      "metadata": {
        "id": "cRyE9z0Ew7mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning"
      ],
      "metadata": {
        "id": "lybpFyc5WrGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our baseline model serves as a reference point for evaluating the performance of our more advanced model. With this simple approach we can get a sense of what is achieved in terms of accuracy and to identify any issues with the data. With the results from the baseline model we can make improvements and modifications to achieve a higher accuracy in the advanced model, by changing the amount of convolutional layers, activation functions, and testing out other layer features."
      ],
      "metadata": {
        "id": "xuf23epf_ujb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline Model"
      ],
      "metadata": {
        "id": "OkF0Rqq-haog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()"
      ],
      "metadata": {
        "id": "jt1NKYoUnneA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (50, 50, 3)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Input(shape=input_shape))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "ve1vPvoMiOKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=8,\n",
        "                              restore_best_weights=True, verbose=1)"
      ],
      "metadata": {
        "id": "KsY5zpgbSzQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "b9-VLMWcnRFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.3,\n",
        "                    callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "FRMhZXUfnXhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'test accuracy: {test_accuracy:.3g}')"
      ],
      "metadata": {
        "id": "DkkW08UCn7Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Commentary for Statement for Test Accuracy to Consider Baseline Benchmark to Achieve a Higher Score Against for our Complex Model"
      ],
      "metadata": {
        "id": "C4mU0FcPMBNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complex Model"
      ],
      "metadata": {
        "id": "MtDVmEGvYGUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()"
      ],
      "metadata": {
        "id": "x5MaZepcsFpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Will Showcase Mean Validation Accuracy Values for Each Random Search Models to Show Model with Highest Value"
      ],
      "metadata": {
        "id": "pd6gwbJIM17R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scores_to_dataframe(scores):\n",
        "    \"\"\" Return hyperparameters and scores in a data frame. \"\"\"\n",
        "\n",
        "    params_list, acc_list = scores\n",
        "\n",
        "    params = pd.DataFrame(params_list)\n",
        "    accs = pd.Series(acc_list)\n",
        "    scores_df = pd.concat([params, accs], axis=1)\n",
        "\n",
        "    return scores_df"
      ],
      "metadata": {
        "id": "kqslTNabMxCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(conv_layers=3, num_filters=32, act_fun='relu', dropout_rate=0.5, dense_layers=3):\n",
        "  input_shape = (50, 50, 3)\n",
        "  inputs = Input(input_shape)\n",
        "  x = inputs\n",
        "  num_filters_doubled = num_filters * 2\n",
        "\n",
        "  for i in range(conv_layers):\n",
        "    if (i == 0):\n",
        "      x = layers.Conv2D(num_filters, (3, 3), padding='same')(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.Activation(act_fun)(x)\n",
        "      x = layers.MaxPooling2D(2, 2)(x)\n",
        "      x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    else:\n",
        "      x = layers.Conv2D(num_filters_doubled, (3, 3), padding='same')(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.Activation(act_fun)(x)\n",
        "      x = layers.MaxPooling2D(2, 2)(x)\n",
        "      x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "  x = layers.Flatten()(x)\n",
        "\n",
        "  for j in range(dense_layers):\n",
        "    if (j == 0):\n",
        "      x = layers.Dense(num_filters_doubled)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.Activation(act_fun)(x)\n",
        "      x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    else:\n",
        "      x = layers.Dense(num_filters)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.Activation(act_fun)(x)\n",
        "      x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "  x = layers.Dense(2, activation='softmax')(x)\n",
        "  return Model(inputs, x)"
      ],
      "metadata": {
        "id": "34eZnuPACImu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_params = {\n",
        "    'conv_layers': 3,\n",
        "    'num_filters': 32,\n",
        "    'act_fun': 'relu',\n",
        "    'dropout_rate': 0.5,\n",
        "    'dense_layers': 3,\n",
        "    'optimizer': 'adam',\n",
        "}"
      ],
      "metadata": {
        "id": "63R_7EvNNVaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_params(params, verbose=1):\n",
        "  # default parameters are used if not supplied\n",
        "  pars = param_grid.copy()\n",
        "  pars.update(params)\n",
        "\n",
        "  conv_layers = pars['conv_layers']\n",
        "  num_filters = pars['num_filters']\n",
        "  act_fun = pars['act_fun']\n",
        "  dropout_rate = pars['dropout_rate']\n",
        "  dense_layers = pars['dense_layers']\n",
        "  optimizer = params['optimizer']\n",
        "\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=8,\n",
        "                                restore_best_weights=True, verbose=1)\n",
        "  reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                          patience=4, min_lr=0.000001, verbose=1)\n",
        "\n",
        "  model = get_model(conv_layers=conv_layers, num_filters=num_filters, act_fun=act_fun,\n",
        "                    dropout_rate=dropout_rate, dense_layers=dense_layers)\n",
        "\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=\"binary_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  history = model.fit(X_train, y_train, epochs=20,\n",
        "                      callbacks=[early_stopping, reduce_lr_on_plateau],\n",
        "                      batch_size=32, validation_split=0.3, verbose=verbose)\n",
        "\n",
        "  mean_acc = np.mean(history.history['val_accuracy'][-2:])\n",
        "  return pars, mean_acc, history"
      ],
      "metadata": {
        "id": "ZU8O3Ux5nPPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "36 Num_Tests Represents 50% of the Possible Parameter Combinations"
      ],
      "metadata": {
        "id": "8-JiQtAZQl_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_search(param_grid, num_tests=36, random_state=None, verbose=1):\n",
        "  # create a list of unique parameter combinations\n",
        "  param_combs = list(ParameterGrid(param_grid))\n",
        "  if len(param_combs) < num_tests:\n",
        "    num_tests = len(param_combs)\n",
        "  random_combs = np.random.choice(param_combs, size=num_tests, replace=False)\n",
        "  # evaluate each of the combinations\n",
        "  params_list = []\n",
        "  acc_list = []\n",
        "  for params in random_combs:\n",
        "    print(f\"params: {params}\")\n",
        "    pars, acc, history = evaluate_params(params, verbose=verbose)\n",
        "    params_list.append(pars)\n",
        "    acc_list.append(acc)\n",
        "  return params_list, acc_list"
      ],
      "metadata": {
        "id": "OcLwfgRInRkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "  \"conv_layers\": [3, 4, 5],\n",
        "  \"num_filters\": [32, 64],\n",
        "  \"act_fun\": ['relu', 'elu'],\n",
        "  \"dropout_rate\": [0.5],\n",
        "  \"dense_layers\": [2, 3],\n",
        "  \"optimizer\": ['adam', 'rmsprop', 'nadam'],\n",
        "}\n",
        "\n",
        "results = random_search(param_grid)"
      ],
      "metadata": {
        "id": "TAys4caenTz4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_to_dataframe(results)"
      ],
      "metadata": {
        "id": "07ZVoe8VNkYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model: Test 4"
      ],
      "metadata": {
        "id": "y7TzNrI-i1lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_model(conv_layers=4, num_filters=64, act_fun='relu', dropout_rate=0.5, dense_layers=3)"
      ],
      "metadata": {
        "id": "BY7AHyckS8oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1)\n",
        "reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', patience=4, min_lr=0.000001, verbose=1)"
      ],
      "metadata": {
        "id": "hmBwwDWxTSh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "TWdd-AewTWgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=50,\n",
        "                    callbacks=[early_stopping, reduce_lr_on_plateau],\n",
        "                    batch_size=32, validation_split=0.3, verbose=1)"
      ],
      "metadata": {
        "id": "HUVNDkMnTmYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'test accuracy: {test_accuracy:.3g}')"
      ],
      "metadata": {
        "id": "IVci-Pl9TuIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n"
      ],
      "metadata": {
        "id": "ccqHH5y6ZQGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  We discovered that the best parameters to train our complex model are {conv_layers = 4, num_filters = 64, act_fun = 'relu', dropout_rate = 0.5, dense_layers = 3}, achieving an accuracy of 88.54%. In our complex model, we used 32 filters in the first convolutional layer and doubled the filters in every subsequent layer to 64. To enhance performance and reduce overfitting, we incorporated BatchNormalization(), MaxPooling(), and Dropout() techniques. For high quality optimization, we performed random search over a parameter grid with 72 unique model combinations. Additionally, we had two callbacks: EarlyStopping and Reduce Learning Rate on Plateau, which helped reduce overfitting and provided incremental improvements in accuracy.\n",
        "\n",
        "  Our model significantly outperformed the baseline model, which is crucial for our dataset involving IDC, the most common form of breast cancer. The model predicts 0 for \"no breast cancer\" and 1 for \"breast cancer.\" Given the life-and-death implications of early and accurate breast cancer detection, achieving high accuracy is very crucial and important. Our results demonstrate that this complex model could potentially assist in reliable IDC detection, and help fight against breast cancer.\n",
        "\n",
        "  Some potential improvements that could be implemented was data augmentation on the images, because we trained on a sample of the whole dataset. This could have increased the diversity of the training set by applying transformations such as rotations or zooming, helping the model generalize the images better. Instead of using random search for hyperparameter tuning, we could have used Bayesian optimization or grid search, which might have provided better accuracy results by using the parameter space more efficiently.\n"
      ],
      "metadata": {
        "id": "2HHtTli540Ib"
      }
    }
  ]
}